#!/usr/bin/env python3

import datetime
import toml, json
import requests
from pyquery import PyQuery
import pygit2
import subprocess
import re
import pathlib
import os
import os.path
from collections import OrderedDict
from copy import copy, deepcopy

repo_path = '/home/garrison/Personal/wikiotics-static'
repo = pygit2.Repository(repo_path)

repo.checkout('refs/heads/master')
branch_name = '{}-migration'.format(datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))
branch = repo.branches.local.create(branch_name, repo[repo.head.target])
branch_ref = 'refs/heads/' + branch_name
repo.checkout(branch_ref)

cache_dir = '/home/garrison/Personal/wikiotics-migration/.cache'
pathlib.Path(cache_dir).mkdir(parents=True, exist_ok=True)

"currently assumes utf-8 text"
def cache_http_get(url, filename):
    filename = os.path.join(cache_dir, filename)
    if not os.path.isfile(filename):
        r = requests.get(url)
        r.raise_for_status()
        s = r.text
        with open(filename, 'w') as f:
            f.write(s)
    with open(filename) as f:
        return f.read()

contributors_dict = {}

def handle_wikitext(front_matter, js, urn):
    # DONE on main site: disable macros; get old interwiki links working from ductus rev 5fc694545542e345ea64f860d823caf719a280eb
    # https://github.com/wikiotics/ductus/blob/master/ductus/modules/textwiki/templatetags/textwiki.py
    if not js['blob']['text']:
        text = ''
    else:
        url = 'https://old.wikiotics.org/urn/{}'.format(urn.replace(':', '/'))
        d = PyQuery(cache_http_get(url, '{}.html'.format(urn)))
        text = d('.ductus_textwiki_content').html()
        if text is None:
            text = ''
    if 'natural_language' in js['blob']:
        natural_language = js['blob']['natural_language']
        front_matter['languageCode'] = natural_language
    content = subprocess.Popen('pandoc -f html -t commonmark',stdin=subprocess.PIPE,stdout=subprocess.PIPE, shell=True).communicate(text.encode('utf-8'))[0].decode('utf-8')
    if content.startswith('# '):
        first_line, _, content = content.partition('\n')
        front_matter['title'] = first_line.partition('# ')[2].replace('\\!', '!')
        content = content.lstrip('\n')
    if 'tags' in js:
        front_matter['tags'] = sorted([t['value'] for t in js['tags']['array']])
    return content

def fixup_interaction(n):
    if 'prompt' in n:
        n['prompt'] = [int(a) for a in n['prompt'].split(',')]
    for name in 'answer', 'audio', 'transcript':
        if name in n:
            n[name] = int(n[name])
    return n

fqn_dict = {
    '{http://wikiotics.org/ns/2009/wikitext}wikitext': None,
    '{http://wikiotics.org/ns/2011/flashcards}flashcard_deck': 'lesson',
    '{http://wikiotics.org/ns/2011/flashcards}flashcard': None,
    '{http://wikiotics.org/ns/2009/picture}picture': 'picture',
    '{http://wikiotics.org/ns/2011/phrase}phrase': 'phrase',
    '{http://wikiotics.org/ns/2010/audio}audio': 'audio',
    # interactions
    '{http://wikiotics.org/ns/2011/flashcards}audio_lesson_interaction': 'podcast',
    '{http://wikiotics.org/ns/2011/flashcards}choice_interaction': 'choice',
    '{http://wikiotics.org/ns/2011/flashcards}story_book_interaction': 'storybook',
}

def extract_side_resource(n):
    resource = n['resource']
    if resource is None:
        return {'type': 'empty'}
    if resource['fqn'] in ('{http://wikiotics.org/ns/2009/picture}picture', '{http://wikiotics.org/ns/2010/audio}audio'):
        resource['blob_href'] = resource['blob']['href']
        resource['mime_type'] = resource['blob']['mime_type']
        del resource['blob']
        resource['href'] = n['href']
    else:
        assert resource['fqn'] == '{http://wikiotics.org/ns/2011/phrase}phrase'
        resource['text'] = resource['phrase']['text']
        del resource['phrase']
    return resource

def fixup(obj):
    assert not isinstance(obj, OrderedDict)
    if isinstance(obj, list):
        return [fixup(a) for a in obj]
    elif isinstance(obj, dict):
        for name in ('array', 'value'):
            if name in obj:
                assert len(obj) == 1
                return fixup(obj[name])
        if 'headings' in obj:
            obj['headings'] = [n['text'] for n in obj['headings']['array']]
        if 'interactions' in obj:
            obj['interactions'] = [fixup_interaction(n['resource']) for n in obj['interactions']['array']]
        if 'credit' in obj:
            d = {}
            if 'title' in obj['credit']:
                d['title'] = obj['credit']['title']['text']
            if 'original_url' in obj['credit']:
                d['original_url'] = obj['credit']['original_url']['href']
            if 'author' in obj['credit']:
                d['author'] = obj['credit']['author']['text']
            if 'author_url' in obj['credit']:
                d['author_url'] = obj['credit']['author_url']['href']
            if 'common' in obj and 'licenses' in obj['common']:
                licenses = [x['href'] for x in obj['common']['licenses']['array']]
                assert len(licenses) == 1
                d['license'] = licenses[0].replace('http:', 'https:')
                del obj['common']
            obj['credit'] = d
        if 'common' in obj:
            if 'licenses' in obj['common']:
                licenses = [x['href'] for x in obj['common']['licenses']['array']]
                assert licenses == ['http://creativecommons.org/licenses/by-sa/3.0/']
            del obj['common']
        if 'cards' in obj:
            obj['cards'] = [n['resource'] for n in obj['cards']['array']]
        if 'sides' in obj:
            obj['sides'] = [extract_side_resource(n) for n in obj['sides']['array']]
            if 'headings' in obj:
                assert len(obj['sides']) == len(obj['headings'])
        if 'dividers' in obj:
            obj['dividers'] = [int(a) for a in obj['dividers'].split(',')]
        if 'fqn' in obj:
            mytype = fqn_dict[obj['fqn']]
            del obj['fqn']
            if mytype is not None:
                obj['type'] = mytype
        rv = OrderedDict()
        for k in sorted(obj.keys()):
            if k == 'parents':
                continue
            rv[k] = fixup(obj[k])
        return rv
    else:
        return obj

failed = []

def handle_lesson(front_matter, js, urn):
    # https://github.com/wikiotics/ductus/blob/master/ductus/modules/picture/ductmodels.py
    # https://github.com/wikiotics/ductus/blob/master/ductus/modules/flashcards/ductmodels.py
    js = copy(js)
    # Deal with parents/contributors
    contributors = set()
    parents = js['common']['parents']
    assert len(parents) in (0, 1)
    for parent in parents:
        try:
            contributors.update(contributors_dict[parent])
        except KeyError:
            failed.append((parent, urn, front_matter['title']))
        contributors.add(js['common']['author']['text'])
    contributors = sorted(contributors)
    contributors_dict['urn:' + urn] = contributors
    js['contributors'] = contributors
    # Fix up all remaining front matter
    for k, v in fixup(js).items():
        front_matter[k] = v

handler_dict = {
    '{http://wikiotics.org/ns/2009/wikitext}wikitext': handle_wikitext,
    '{http://wikiotics.org/ns/2009/picture}picture': handle_lesson,
    '{http://wikiotics.org/ns/2011/flashcards}flashcard_deck': handle_lesson,
}

for i, rev in enumerate(toml.load("revision-history.toml")['revisions']):
    print(i, '\t', end='')
    output_filename = 'content/{}.md'.format(rev['page'])
    output_path = os.path.join(repo_path, output_filename)
    pathlib.Path(os.path.dirname(output_path)).mkdir(parents=True, exist_ok=True)
    index = repo.index
    if rev['urn']:
        url = 'https://old.wikiotics.org/urn/{}?view=resource_json'.format(rev['urn'].replace(':', '/'))
        print(url)
        js = json.loads(cache_http_get(url, '{}.json'.format(rev['urn'])))
        front_matter = OrderedDict()
        front_matter['title'] = rev['page'].rpartition('/')[2].replace('_', ' ')
        content = handler_dict[js['fqn']](front_matter, js, rev['urn'])
        if 'tags' in front_matter:
            tags = front_matter['tags']
            temp = []
            while tags:
                x = tags.pop()
                if x.startswith('source-language:'):
                    front_matter.setdefault('source-languages', []).append(x.partition(':')[2])
                elif x.startswith('target-language:'):
                    front_matter.setdefault('target-languages', []).append(x.partition(':')[2])
                else:
                    temp.append(x)
            while temp:
                tags.append(temp.pop())
            tags.sort()
            if not tags:
                del front_matter['tags']
        with open(output_path, 'w') as f:
            f.write("+++\n{}+++\n".format(toml.dumps(front_matter)))
            if content:
                f.write('\n')
                f.write(content)
        # https://www.pygit2.org/recipes/git-add-reset.html
        index.add(output_filename)
    else:
        if not os.path.isfile(output_path):
            print("skipping deletion - page does not exist: {}".format(rev['page']))
            continue
        print("Removing {}".format(rev['page']))
        index.remove(output_filename)
        os.remove(output_path)
    index.write()
    # https://www.pygit2.org/recipes/git-cherry-pick.html
    # https://stackoverflow.com/questions/29469649/create-a-commit-using-pygit2
    author_email = '{}@wikiotics.org'.format(rev['author'].replace('@', '_') if 'author' in rev else rev['author_ip'])
    author = pygit2.Signature(author_email, author_email, time=int(rev['timestamp'].timestamp()))
    committer = pygit2.Signature("Automated migration from ductus", 'migration@wikiotics.org')
    tree = index.write_tree()
    log_message = rev.get('log_message', '(No log message)')
    log_message += '\n\nAutomated import from Ductus\nhttps://github.com/wikiotics/migration-from-ductus\n\nurn:{}'.format(rev['urn'])
    if rev['urn']:
        parents = js['common']['parents']
        for parent in parents:
            log_message += '\n\nParent: {}'.format(parent)
    repo.create_commit(branch_ref, author, committer, log_message, tree, [repo.head.target])

print("Parents not found:")
for f in failed:
    print(f)
